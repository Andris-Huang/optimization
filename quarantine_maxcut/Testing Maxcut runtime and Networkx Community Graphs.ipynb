{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent of this notebook is two-fold:\n",
    "\n",
    "1) Try to see which networkx graph generators most closely mimic the data of Cornell university student network given here https://osf.io/t7n9f/\n",
    "\n",
    "2) Test the time dependence of Max-Cut on the size of a graph generated by the most accurate generator determined in part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.generators.community as community\n",
    "from networkx.generators.random_graphs import connected_watts_strogatz_graph as small_world\n",
    "from networkx.generators.random_graphs import powerlaw_cluster_graph as cluster\n",
    "import ndlib\n",
    "import future.utils\n",
    "import warnings\n",
    "import time\n",
    "from random import randint\n",
    "from random import sample\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QUBO dict for D-Wave to optimize\n",
    "def maxcut_qubo(G):\n",
    "    # The Hamiltonian is H = sum(Pauli_Z(i) x Pauli_Z(j) - I)/2\n",
    "    # The eigenvalue is the negation of the edges in cut solution\n",
    "    # The QUBO should be -xi-xj+2xixj, we label it as Q\n",
    "    Q = defaultdict(int)\n",
    "    for u, v in G.edges:\n",
    "        Q[(u,u)]+= -1\n",
    "        Q[(v,v)]+= -1\n",
    "        Q[(u,v)]+= 2\n",
    "    return Q\n",
    "\n",
    "# Invoke D-Wave annealer\n",
    "def solve(Q, chainstrength=8, numruns=100):\n",
    "    # Run the QUBO on the solver from your config file\n",
    "    sampler = EmbeddingComposite(DWaveSampler(solver={'qpu': True}))\n",
    "    response = sampler.sample_qubo(Q, num_reads=numruns)\n",
    "    energies = iter(response.data())\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different graph generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://osf.io/t7n9f/?show=view gives the \n",
    "##### target stats for Cornell University model:\n",
    "\n",
    "Number of unique nodes  3,800\n",
    "\n",
    "Number of unique edges 287,327 \n",
    "\n",
    "Network density .040\n",
    "\n",
    "Clustering coefficient .480\n",
    "\n",
    "Average geodesic distance 2.233\n",
    "\n",
    "Network diameter (largest observed distance) 65\n",
    "\n",
    "Average k-step reach centrality: k=1::   0.040,  k=2::   0.725,  k=3::   0.994,  k=4::   0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_avg_distance(G, samples):\n",
    "    distance_sum = 0\n",
    "    for i in range(samples):\n",
    "        pair = sample(list(G.nodes()), 2)\n",
    "        #print(pair)\n",
    "        distance = len(nx.shortest_path(G, pair[0], pair[1]))\n",
    "        #print(distance)\n",
    "        distance_sum += distance\n",
    "    return distance_sum/samples\n",
    "\n",
    "def random_avg_clustering_coeff(G, samples):\n",
    "    sampled_nodes = sample(list(G.nodes()), samples)\n",
    "    clustering_dict = nx.clustering(G, sampled_nodes)\n",
    "    return np.mean(np.array(list(clustering_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### connected_watts_strogatz_graph(n, k, p, tries=100, seed=None)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "n: number of nodes \n",
    "\n",
    "k: how many nearest neighbors in ring to connect each node to \n",
    "\n",
    "p: prob to rewire edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_small_world = small_world(3800, 152, .15)\n",
    "print('density: ', nx.density(big_small_world))\n",
    "print('cluster coeff:', random_avg_clustering_coeff(big_small_world, 1000))\n",
    "print('avg distance:', random_avg_distance(big_small_world, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matching density and clustering coefficient, avg geodesic distance a bit too high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### newman_watts_strogatz_graph(n, k, p, seed=None)\n",
    "\n",
    "Returns a Newman–Watts–Strogatz small-world graph.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "n (int) – The number of nodes.\n",
    "\n",
    "k (int) – Each node is joined with its k nearest neighbors in a ring topology.\n",
    "\n",
    "p (float) – The probability of adding a new edge for each edge.\n",
    "\n",
    "seed (integer, random_state, or None (default)) – Indicator of random number generation state. See Randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density:  0.05917637605464042\n",
      "cluster coeff: 0.35473747639591363\n",
      "avg distance: 2.938\n"
     ]
    }
   ],
   "source": [
    "big_nw_small_world = nx.generators.random_graphs.newman_watts_strogatz_graph(3800, 150, .5)\n",
    "print('density: ', nx.density(big_nw_small_world))\n",
    "print('cluster coeff:', random_avg_clustering_coeff(big_nw_small_world, 1000))\n",
    "print('avg distance:', random_avg_distance(big_nw_small_world, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable to improve on avg distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## power law cluster graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### powerlaw_cluster_graph(n, m, p, seed=None) \n",
    "\n",
    "Parameters:\n",
    "\n",
    "n (int) – the number of nodes\n",
    "\n",
    "m (int) – the number of random edges to add for each new node\n",
    "\n",
    "p (float,) – Probability of adding a triangle after adding a random edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_cluster = cluster(3800, 70, 1)\n",
    "print('density: ', nx.density(big_cluster))\n",
    "print('cluster coeff:', random_avg_clustering_coeff(big_cluster, 1000))\n",
    "print('avg distance:', random_avg_distance(big_cluster, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bound on clustering coefficient, cant get it above around .25, so does not match data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## community graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### planted_partition_graph(l, k, p_in, p_out, seed=None, directed=False)[source]\n",
    "Returns the planted l-partition graph.\n",
    "\n",
    "This model partitions a graph with n=l*k vertices in l groups with k vertices each. Vertices of the same group are linked with a probability p_in, and vertices of different groups are linked with probability p_out.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "l (int) – Number of groups\n",
    "\n",
    "k (int) – Number of vertices in each group\n",
    "\n",
    "p_in (float) – probability of connecting vertices within a group\n",
    "\n",
    "p_out (float) – probability of connected vertices between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg = community.planted_partition_graph(10, int(3800/10), 1, .05)\n",
    "print('density: ', nx.density(ppg))\n",
    "print('cluster coeff:', random_avg_clustering_coeff(ppg, 20))\n",
    "print('avg distance:', random_avg_distance(ppg, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cant seem to get density low and clustering high enough simulataneously with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gaussian_random_partition_graph(n, s, v, p_in, p_out, directed=False, seed=None)[source]\n",
    "Generate a Gaussian random partition graph.\n",
    "\n",
    "A Gaussian random partition graph is created by creating k partitions each with a size drawn from a normal distribution with mean s and variance s/v. Nodes are connected within clusters with probability p_in and between clusters with probability p_out[1]\n",
    "\n",
    "Parameters:\n",
    "\n",
    "n (int) – Number of nodes in the graph\n",
    "\n",
    "s (float) – Mean cluster size\n",
    "\n",
    "v (float) – Shape parameter. The variance of cluster size distribution is s/v.\n",
    "\n",
    "p_in (float) – Probabilty of intra cluster connection.\n",
    "\n",
    "p_out (float) – Probability of inter cluster connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpg = community.gaussian_random_partition_graph(3800, 1000, 100, .6, .1)\n",
    "print('density: ', nx.density(grpg))\n",
    "print('cluster coeff:', random_avg_clustering_coeff(grpg, 20))\n",
    "print('avg distance:', random_avg_distance(grpg, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasn't able to get the exact stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the Watts-Strogatz graphs get closest to the Cornell class enrollment network. This is also suggested in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does D-Wave max-cut time depend on watts-strogatz graph size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4444444444444444, 0.13793103448275862, 0.08163265306122448, 0.06060606060606061, 0.040268456375838924, 0.0446927374301676]\n",
      "[0.43999999999999995, 0.5, 0.43, 0.4709523809523809, 0.4766666666666667, 0.45]\n",
      "[3.1, 4.6, 5.2, 5.2, 5.9, 5.2]\n"
     ]
    }
   ],
   "source": [
    "densities, cluster_coeffs, avg_distances = [], [], []\n",
    "a = small_world(10, 4, .05)\n",
    "densities.append(nx.density(a))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(a, 10))\n",
    "avg_distances.append(random_avg_distance(a, 10))\n",
    "b = small_world(30, 4, 0)\n",
    "densities.append(nx.density(b))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(b, 10))\n",
    "avg_distances.append(random_avg_distance(b, 10))\n",
    "c = small_world(50, 4, .05)\n",
    "densities.append(nx.density(c))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(c, 10))\n",
    "avg_distances.append(random_avg_distance(c, 10))\n",
    "d = small_world(100, 6, .1)\n",
    "densities.append(nx.density(d))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(d, 10))\n",
    "avg_distances.append(random_avg_distance(d, 10))\n",
    "e = small_world(150, 7, .1)\n",
    "densities.append(nx.density(e))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(e, 10))\n",
    "avg_distances.append(random_avg_distance(e, 10))\n",
    "f = small_world(180, 9, .11)\n",
    "densities.append(nx.density(f))\n",
    "cluster_coeffs.append(random_avg_clustering_coeff(f, 10))\n",
    "avg_distances.append(random_avg_distance(f, 10))\n",
    "print(densities) \n",
    "print(cluster_coeffs) \n",
    "print(avg_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed size 10\n",
      "completed size 30\n",
      "completed size 50\n",
      "completed size 100\n",
      "completed size 150\n",
      "completed size 180\n",
      "[2.3966965675354004, 3.1521782875061035, 2.5011050701141357, 2.6607565879821777, 8.48445463180542, 7.3369739055633545]\n"
     ]
    }
   ],
   "source": [
    "small_world_graphs = [a, b, c, d, e, f]\n",
    "small_world_times = []\n",
    "small_world_start_time = time.time()\n",
    "small_world_previous_time = small_world_start_time\n",
    "for graph, size in zip(small_world_graphs, [10, 30, 50, 100, 150, 180]):\n",
    "    result = solve(maxcut_qubo(graph))\n",
    "    small_world_current_time = time.time()\n",
    "    small_world_times.append(small_world_current_time - small_world_previous_time)\n",
    "    small_world_previous_time = small_world_current_time\n",
    "    print(f'completed size {size}')\n",
    "print(small_world_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: We were able to embed small world (Watts-Strogatz) graphs of size up to 180 on D-Wave hardware in less than 10 seconds. We have not successfully been able to embed a graph of 200 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors:\n",
    "    James Sud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwaveCorona",
   "language": "python",
   "name": "dwavecorona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
